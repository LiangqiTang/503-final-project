{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "693d9489-ef15-4364-a5b9-c0295a02f641",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import sklearn.model_selection\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b8e2ad2-ea50-4428-b861-148bb50d9c51",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8000, 56), (4000, 55))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the data\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42e184f3-8f8c-4adc-8c3c-e8f1e19da1c7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8000, 62), (4000, 61))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data preprocessing(one-hot encoding)\n",
    "train = pd.get_dummies(train, columns = ['district'])\n",
    "test = pd.get_dummies(test, columns = ['district'])\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f961437b-b9b0-4a2b-b931-e146279b754a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# extract X and y\n",
    "\n",
    "X = train.drop(columns = [\"y\",\"SEQN\"]).values\n",
    "y = train.y.values\n",
    "\n",
    "# X = train[[\"self_eval\",\"teacher_eval\",\"extracurricular\",\"district_1\",\"district_2\",\"district_3\",\"district_4\",\"district_5\",\"district_6\",\"district_7\"]].values\n",
    "# y = train.y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "293e74d4-88df-4ec8-9193-285ba25abeda",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# split training data into train and validation\n",
    "X_train, X_valid, y_train, y_valid = sklearn.model_selection.train_test_split(X, y, test_size = 0.2, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "475402e5-d97c-4e37-9d6c-49f29e1befa3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# convert training data into torch tensors\n",
    "\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32).reshape(-1,1)\n",
    "X_valid = torch.tensor(X_valid, dtype=torch.float32)\n",
    "y_valid = torch.tensor(y_valid, dtype=torch.float32).reshape(-1,1)\n",
    "\n",
    "# X = torch.tensor(X, dtype=torch.float32)\n",
    "# y = torch.tensor(y, dtype=torch.float32).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6c1e817-4cb6-47a9-ac37-82aac8f1a43e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create network(model)\n",
    "# raw model\n",
    "class Net1(nn.Module):\n",
    "    # constructor\n",
    "    def __init__(self, H1, H2, D_out):\n",
    "        super(Net1, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.LazyLinear(H1),\n",
    "            nn.ReLU(),\n",
    "            nn.LazyLinear(H2),\n",
    "            nn.ReLU(),\n",
    "            nn.LazyLinear(D_out))\n",
    "        \n",
    "    # prediction\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e0ece7b-9151-4b86-a6b3-e8cb44f74b56",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create network(model)\n",
    "# with dropout model\n",
    "class Net2(nn.Module):\n",
    "    # constructor\n",
    "    def __init__(self, H1, H2, D_out):\n",
    "        super(Net2, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.LazyLinear(H1),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p = 0.2),\n",
    "            nn.LazyLinear(H2),\n",
    "            nn.ReLU(),\n",
    "            nn.LazyLinear(D_out))\n",
    "        \n",
    "    # prediction\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a61fa87-47d8-438a-9ab8-8bac5cfe1fa8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create network(model)\n",
    "# deeper model\n",
    "class Net3(nn.Module):\n",
    "    # constructor\n",
    "    def __init__(self, H1, H2, H3, H4, H5, H6, D_out):\n",
    "        super(Net3, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.LazyLinear(H1),\n",
    "            nn.ReLU(),\n",
    "            nn.LazyLinear(H2),\n",
    "            nn.ReLU(),\n",
    "            nn.LazyLinear(H3),\n",
    "            nn.ReLU(),\n",
    "#            nn.Dropout(p = 0.02),\n",
    "            nn.LazyLinear(H4),\n",
    "            nn.ReLU(),\n",
    "#            nn.Dropout(p = 0.2),\n",
    "            nn.LazyLinear(H5),\n",
    "            nn.ReLU(),\n",
    "            nn.LazyLinear(H6),\n",
    "            nn.ReLU(),\n",
    "            nn.LazyLinear(D_out))\n",
    "        \n",
    "    # prediction\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "b325e1e5-578a-4ffd-9ebc-a7ee959dff12",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create network(model)\n",
    "# deeper model\n",
    "class Net4(nn.Module):\n",
    "    # constructor\n",
    "    def __init__(self, H1, H2, H3, H4, H5, H6, H7, H8, D_out):\n",
    "        super(Net4, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.LazyLinear(H1),\n",
    "            nn.ReLU(),\n",
    "#            nn.BatchNorm1d(H1),\n",
    "            nn.LazyLinear(H2),\n",
    "            nn.ReLU(),\n",
    "#            nn.BatchNorm1d(H2),\n",
    "            nn.LazyLinear(H3),\n",
    "            nn.ReLU(),\n",
    "#            nn.BatchNorm1d(H3),\n",
    "#            nn.Dropout(p = 0.2),\n",
    "            nn.LazyLinear(H4),\n",
    "            nn.ReLU(),\n",
    "#            nn.BatchNorm1d(H4),\n",
    "#            nn.Dropout(p = 0.5),\n",
    "            nn.LazyLinear(H5),\n",
    "            nn.ReLU(),\n",
    "#            nn.BatchNorm1d(H5),\n",
    "#            nn.Dropout(p = 0.5),\n",
    "            nn.LazyLinear(H6),\n",
    "            nn.ReLU(),\n",
    "#            nn.BatchNorm1d(H6),\n",
    "#            nn.Dropout(p = 0.2),\n",
    "            nn.LazyLinear(H7),\n",
    "            nn.ReLU(),\n",
    "#            nn.BatchNorm1d(H7),\n",
    "            nn.LazyLinear(H8),\n",
    "            nn.ReLU(),\n",
    "#            nn.BatchNorm1d(H8),\n",
    "            nn.LazyLinear(D_out))\n",
    "        \n",
    "    # prediction\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "8e4eeeeb-404e-4f93-a9fd-f461445d0479",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create network(model)\n",
    "# deeper model with batch normalization\n",
    "class Net5(nn.Module):\n",
    "    # constructor\n",
    "    def __init__(self, H1, H2, H3, H4, H5, H6, D_out):\n",
    "        super(Net5, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.LazyLinear(H1),\n",
    "            nn.ReLU(),\n",
    "#            nn.BatchNorm1d(H1),\n",
    "            nn.LazyLinear(H2),\n",
    "            nn.ReLU(),\n",
    "#            nn.BatchNorm1d(H2),\n",
    "            nn.LazyLinear(H3),\n",
    "            nn.ReLU(),\n",
    "#            nn.Dropout(p = 0.2),\n",
    "#            nn.BatchNorm1d(H3),\n",
    "            nn.LazyLinear(H4),\n",
    "            nn.ReLU(),\n",
    "#            nn.Dropout(p = 0.2),\n",
    "#            nn.BatchNorm1d(H4),\n",
    "            nn.LazyLinear(H5),\n",
    "            nn.ReLU(),\n",
    "#            nn.BatchNorm1d(H5),\n",
    "            nn.LazyLinear(H6),\n",
    "            nn.ReLU(),\n",
    "#            nn.BatchNorm1d(H6),\n",
    "            nn.LazyLinear(D_out))\n",
    "        \n",
    "    # prediction\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bbb0cfba-f411-4a12-9e83-dc5a165c9d2b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create loss function(criterion)\n",
    "mae = nn.L1Loss()\n",
    "mse = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f427d06d-d23c-4e01-bea8-9a70a5885e23",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create data_loader to split into batches(train_loader and test_loader)\n",
    "train_loader = DataLoader(dataset=list(zip(X_train,y_train)), batch_size=40, shuffle=True)\n",
    "test_loader = DataLoader(dataset=list(zip(X_valid,y_valid)), batch_size=40, shuffle=False)\n",
    "\n",
    "# train_loader = DataLoader(dataset=list(zip(X,y)), batch_size=40, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "dd267642-2b3f-42fd-9834-2158eddaf2a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Train with validation loop\n",
    "def train(model, criterion, train_loader, test_loader, optimizer, epochs = 100):\n",
    "    metrics = {'training_loss':[], 'validation_loss':[]}\n",
    "    tbar = tqdm(range(epochs), position=0, leave=True)\n",
    "    for _ in tbar:\n",
    "        loss_train_total = 0\n",
    "        for x, y in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            z = model(x)\n",
    "            loss_train = criterion(z, y)\n",
    "            loss_train.backward()\n",
    "            optimizer.step()\n",
    "            loss_train_total += loss_train.item()\n",
    "        \n",
    "        metrics['training_loss'].append(loss_train_total/len(train_loader))\n",
    "        \n",
    "        loss_valid_total = 0\n",
    "        for x, y in test_loader:\n",
    "            z = model(x)\n",
    "            loss_valid = criterion(z, y)\n",
    "            loss_valid_total += loss_valid.item()\n",
    "            \n",
    "        metrics['validation_loss'].append(loss_valid_total/len(test_loader))\n",
    "        \n",
    "        tbar.set_description(f\"Train loss: {loss_train_total/len(train_loader)}, Validation loss: {loss_valid_total/len(test_loader)}\")\n",
    "            \n",
    "    return metrics\n",
    "\n",
    "# Train without validation loop\n",
    "\n",
    "def train_all(model, criterion, train_loader, optimizer, epochs = 100):\n",
    "    metrics = {'training_loss':[]}\n",
    "    tbar = tqdm(range(epochs), position=0, leave=True)\n",
    "    for _ in tbar:\n",
    "        loss_train_total = 0\n",
    "        for x, y in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            z = model(x)\n",
    "            loss_train = criterion(z, y)\n",
    "            loss_train.backward()\n",
    "            optimizer.step()\n",
    "            loss_train_total += loss_train.item()\n",
    "        \n",
    "        metrics['training_loss'].append(loss_train_total/len(train_loader))\n",
    "        tbar.set_description(f\"Train loss: {loss_train_total/len(train_loader)}\")\n",
    "            \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "908f8866-6c45-4d44-b965-393b615366dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create optimizer(optimizer)\n",
    "\n",
    "# # best result for Net3: epochs = 250\n",
    "# learning_rate = 0.001\n",
    "# model = Net3(64, 128, 256, 256, 128, 64, 1)\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate, weight_decay = 0.01)\n",
    "\n",
    "# # best result for Net3: epochs = 2000, not scale data\n",
    "# learning_rate = 0.0001\n",
    "# model = Net3(64, 128, 256, 256, 128, 64, 1)\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate, weight_decay = 0.01)\n",
    "\n",
    "# best result for Net3: epochs = 2000, not scale data\n",
    "learning_rate = 0.0001\n",
    "model = Net3(64, 128, 256, 256, 128, 64, 1)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate, weight_decay = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "2cb1b339-a4f5-4b9b-a7f2-96df67e8ecb2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train loss: 0.16461123491171747, Validation loss: 0.30694091096520426: 100%|████████████████| 2500/2500 [23:01<00:00,  1.81it/s]\n"
     ]
    }
   ],
   "source": [
    "model_results = train(model, mse, train_loader, test_loader, optimizer, epochs = 2200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "56d46a29-1336-4849-9bee-eb184fb3316f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train loss: 0.19746827345341444: 100%|██████████████████████████████████████████████████████| 2200/2200 [11:57<00:00,  3.07it/s]\n"
     ]
    }
   ],
   "source": [
    "# training with all data\n",
    "model_results = train_all(model, mse, train_loader, optimizer, epochs = 2200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "118997e6-2d44-47c7-9ef0-26266ffffb38",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minimum validation loss: 0.3061361417174339\n",
      "corresponding epoch: 2357\n",
      "last epoch: 0.30694091096520426\n"
     ]
    }
   ],
   "source": [
    "# find the minimum validation loss\n",
    "min_loss = min(model_results['validation_loss'])\n",
    "print(f'minimum validation loss: {min_loss}')\n",
    "\n",
    "# find the epoch of minimum validation loss\n",
    "epoch_min = model_results['validation_loss'].index(min(model_results['validation_loss']))\n",
    "print(f'corresponding epoch: {epoch_min}')\n",
    "\n",
    "# last epoch validation loss\n",
    "epoch_last = model_results['validation_loss'][-1]\n",
    "print(f'last epoch: {epoch_last}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "683bff3f-8a30-430e-97fa-3db0c88fb6ff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(model_results['training_loss'], label = 'train_loss')\n",
    "plt.plot(model_results['validation_loss'], label = 'valid_loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend()\n",
    "_ = plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "0d04be4c-a1a7-4e90-b5f4-12f7bbae632c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# predict on test data\n",
    "X_new = test.drop(columns = [\"SEQN\"]).values\n",
    "\n",
    "# scaler = StandardScaler()\n",
    "# scaler.fit(X_new)\n",
    "# X_new = scaler.transform(X_new)\n",
    "\n",
    "X_train = torch.tensor(X_new, dtype=torch.float32)\n",
    "\n",
    "predict = model(X_train)\n",
    "\n",
    "submission = pd.DataFrame({'SEQN':test.SEQN,\n",
    "                           'y':predict.view(-1).detach().numpy()})\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ae88715-46f2-433d-8fe8-32f8ebf6b9ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Train with validation loop\n",
    "def train(model, criterion, train_loader, test_loader, optimizer, epochs):\n",
    "    metrics = {'training_loss':[], 'validation_loss':[]}\n",
    "    tbar = tqdm(range(epochs), position=0, leave=True)\n",
    "    for _ in tbar:\n",
    "        loss_train_total = 0\n",
    "        for x, y in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            z = model(x)\n",
    "            loss_train = criterion(z, y)\n",
    "            loss_train.backward()\n",
    "            optimizer.step()\n",
    "            loss_train_total += loss_train.item()\n",
    "        \n",
    "        metrics['training_loss'].append(loss_train_total/len(train_loader))\n",
    "        \n",
    "        loss_valid_total = 0\n",
    "        for x, y in test_loader:\n",
    "            z = model(x)\n",
    "            loss_valid = criterion(z, y)\n",
    "            loss_valid_total += loss_valid.item()\n",
    "            \n",
    "        metrics['validation_loss'].append(loss_valid_total/len(test_loader))\n",
    "        \n",
    "        tbar.set_description(f\"Train loss: {loss_train_total/len(train_loader)}, Validation loss: {loss_valid_total/len(test_loader)}\")\n",
    "            \n",
    "    return metrics, model\n",
    "\n",
    "# cross validation\n",
    "def train_cv(X, y, criterion, cv, epochs = 1000, learning_rate = 0.0001):\n",
    "    \n",
    "    model_results = []\n",
    "    model_sets = []\n",
    "    \n",
    "    for i, (cv_train, cv_test) in enumerate(cv.split(X)):\n",
    "        \n",
    "        X_train = X[cv_train]\n",
    "        y_train = y[cv_train]\n",
    "        X_valid = X[cv_test]\n",
    "        y_valid = y[cv_test]\n",
    "        \n",
    "        X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "        y_train = torch.tensor(y_train, dtype=torch.float32).reshape(-1,1)\n",
    "        X_valid = torch.tensor(X_valid, dtype=torch.float32)\n",
    "        y_valid = torch.tensor(y_valid, dtype=torch.float32).reshape(-1,1)\n",
    "        \n",
    "        train_loader = DataLoader(dataset=list(zip(X_train,y_train)), batch_size=40, shuffle=True)\n",
    "        test_loader = DataLoader(dataset=list(zip(X_valid,y_valid)), batch_size=40, shuffle=False)\n",
    "        \n",
    "        model = Net3(64, 128, 256, 256, 128, 64, 1)\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate, weight_decay = 0.01)\n",
    "        \n",
    "        train_results = train(model, criterion, train_loader, test_loader, optimizer, epochs)\n",
    "        \n",
    "        model_results.append(train_results[0])\n",
    "        model_sets.append(train_results[1])\n",
    "        \n",
    "    return model_results, model_sets\n",
    "\n",
    "\n",
    "# parallel\n",
    "def wrapper(args):\n",
    "        return train(*args)\n",
    "\n",
    "def train_cv_parallel(X, y, criterion, cv, epochs = 1000, learning_rate = 0.0001):\n",
    "    \n",
    "    pool = Pool()\n",
    "    train_args = []\n",
    "    model_results = []\n",
    "    model_sets = []\n",
    "    \n",
    "    for i, (cv_train, cv_test) in enumerate(cv.split(X)):\n",
    "        \n",
    "        X_train = X[cv_train]\n",
    "        y_train = y[cv_train]\n",
    "        X_valid = X[cv_test]\n",
    "        y_valid = y[cv_test]\n",
    "        \n",
    "        X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "        y_train = torch.tensor(y_train, dtype=torch.float32).reshape(-1,1)\n",
    "        X_valid = torch.tensor(X_valid, dtype=torch.float32)\n",
    "        y_valid = torch.tensor(y_valid, dtype=torch.float32).reshape(-1,1)\n",
    "        \n",
    "        train_loader = DataLoader(dataset=list(zip(X_train,y_train)), batch_size=40, shuffle=True)\n",
    "        test_loader = DataLoader(dataset=list(zip(X_valid,y_valid)), batch_size=40, shuffle=False)\n",
    "        \n",
    "        model = Net3(64, 128, 256, 256, 128, 64, 1)\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate, weight_decay = 0.01)\n",
    "        \n",
    "        train_args.append([model, criterion, train_loader, test_loader, optimizer, epochs])\n",
    "        \n",
    "    results = pool.map(wrapper, train_args)\n",
    "    model_results = list(map(lambda x: x[0], results))\n",
    "    model_sets = list(map(lambda x: x[1], results))\n",
    "        \n",
    "    return model_results, model_sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60fe4391-31a5-4939-99c5-72fdb09ad730",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load the data\n",
    "train_data = pd.read_csv(\"train.csv\")\n",
    "test_data = pd.read_csv(\"test.csv\")\n",
    "\n",
    "# data preprocessing(one-hot encoding)\n",
    "train_data = pd.get_dummies(train_data, columns = ['district'])\n",
    "test_data = pd.get_dummies(test_data, columns = ['district'])\n",
    "\n",
    "X = train_data.drop(columns = [\"y\",\"SEQN\"]).values\n",
    "y = train_data.y.values\n",
    "\n",
    "mse = nn.MSELoss()\n",
    "cv = KFold(n_splits=24, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34ba0aeb-ff6b-4659-ae85-a245946595c8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "Train loss: 0.2564998019952327, Validation loss: 0.295706194308069:  56%|██████████▋        | 1242/2200 [14:34<11:14,  1.42it/s]Process ForkPoolWorker-12:\n",
      "\n",
      "Train loss: 0.25843696816203493, Validation loss: 0.2985517746872372:  56%|█████████▍       | 1225/2200 [14:34<11:36,  1.40it/s]\n",
      "Train loss: 0.26055973725548637, Validation loss: 0.3079444169998169:  56%|█████████▍       | 1226/2200 [14:34<11:34,  1.40it/s]\n",
      "\n",
      "Train loss: 0.2577921023281912, Validation loss: 0.3388391037782033:  56%|██████████▏       | 1238/2200 [14:34<11:19,  1.42it/s]Process ForkPoolWorker-10:\n",
      "Train loss: 0.25734220375306904, Validation loss: 0.2858961174885432:  56%|█████████▌       | 1239/2200 [14:34<11:18,  1.42it/s]Process ForkPoolWorker-15:\n",
      "\n",
      "\n",
      "\n",
      "Process ForkPoolWorker-14:\n",
      "Process ForkPoolWorker-13:\n",
      "Process ForkPoolWorker-9:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "Process ForkPoolWorker-16:\n",
      "Process ForkPoolWorker-11:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.11/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "                    ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.11/multiprocessing/pool.py\", line 48, in mapstar\n",
      "    return list(map(*args))\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "                    ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.11/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "                    ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_16516/1389282335.py\", line 63, in wrapper\n",
      "    return train(*args)\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "                    ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/tmp/ipykernel_16516/2740841832.py\", line 26, in forward\n",
      "    return self.net(x)\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_16516/1389282335.py\", line 63, in wrapper\n",
      "    return train(*args)\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_16516/1389282335.py\", line 10, in train\n",
      "    loss_train = criterion(z, y)\n",
      "                 ^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_16516/1389282335.py\", line 12, in train\n",
      "    optimizer.step()\n",
      "  File \"/opt/conda/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.11/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "                    ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/multiprocessing/pool.py\", line 48, in mapstar\n",
      "    return list(map(*args))\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_16516/1389282335.py\", line 9, in train\n",
      "    z = model(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "                    ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/multiprocessing/pool.py\", line 48, in mapstar\n",
      "    return list(map(*args))\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/multiprocessing/pool.py\", line 48, in mapstar\n",
      "    return list(map(*args))\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_16516/1389282335.py\", line 63, in wrapper\n",
      "    return train(*args)\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/multiprocessing/pool.py\", line 48, in mapstar\n",
      "    return list(map(*args))\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/multiprocessing/pool.py\", line 48, in mapstar\n",
      "    return list(map(*args))\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_16516/1389282335.py\", line 11, in train\n",
      "    loss_train.backward()\n",
      "  File \"/tmp/ipykernel_16516/1389282335.py\", line 63, in wrapper\n",
      "    return train(*args)\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_16516/1389282335.py\", line 63, in wrapper\n",
      "    return train(*args)\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_16516/1389282335.py\", line 8, in train\n",
      "    optimizer.zero_grad()\n",
      "  File \"/opt/conda/lib/python3.11/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "                    ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/torch/_tensor.py\", line 487, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/tmp/ipykernel_16516/1389282335.py\", line 11, in train\n",
      "    loss_train.backward()\n",
      "  File \"/opt/conda/lib/python3.11/multiprocessing/pool.py\", line 48, in mapstar\n",
      "    return list(map(*args))\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_16516/1389282335.py\", line 63, in wrapper\n",
      "    return train(*args)\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/torch/autograd/__init__.py\", line 200, in backward\n",
      "    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "  File \"/tmp/ipykernel_16516/1389282335.py\", line 63, in wrapper\n",
      "    return train(*args)\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_16516/1389282335.py\", line 11, in train\n",
      "    loss_train.backward()\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/torch/_tensor.py\", line 487, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/opt/conda/lib/python3.11/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "                    ^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/torch/autograd/__init__.py\", line 200, in backward\n",
      "    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/torch/_tensor.py\", line 487, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/torch/optim/optimizer.py\", line 456, in zero_grad\n",
      "    with torch.autograd.profiler.record_function(self._zero_grad_profile_name):\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/torch/autograd/profiler.py\", line 492, in __enter__\n",
      "    self.record = torch.ops.profiler._record_function_enter_new(self.name, self.args)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/torch/nn/modules/loss.py\", line 536, in forward\n",
      "    return F.mse_loss(input, target, reduction=self.reduction)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/torch/nn/functional.py\", line 3295, in mse_loss\n",
      "    return torch._C._nn.mse_loss(expanded_input, expanded_target, _Reduction.get_enum(reduction))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/torch/nn/modules/container.py\", line 217, in forward\n",
      "    input = module(input)\n",
      "            ^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/torch/autograd/__init__.py\", line 200, in backward\n",
      "    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/torch/optim/optimizer.py\", line 269, in wrapper\n",
      "    with torch.autograd.profiler.record_function(profile_name):\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/torch/autograd/profiler.py\", line 489, in __init__\n",
      "    self.record = torch.jit.annotate(Optional[\"torch.classes.profiler._RecordFunction\"], None)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/torch/nn/modules/linear.py\", line 114, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/multiprocessing/pool.py\", line 48, in mapstar\n",
      "    return list(map(*args))\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/torch/_ops.py\", line 502, in __call__\n",
      "    return self._op(*args, **kwargs or {})\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/tmp/ipykernel_16516/1389282335.py\", line 63, in wrapper\n",
      "    return train(*args)\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/torch/jit/__init__.py\", line 89, in annotate\n",
      "    def annotate(the_type, the_value):\n",
      "    \n",
      "  File \"/tmp/ipykernel_16516/1389282335.py\", line 11, in train\n",
      "    loss_train.backward()\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/torch/_tensor.py\", line 487, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/torch/autograd/__init__.py\", line 200, in backward\n",
      "    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model_results, model_sets \u001b[38;5;241m=\u001b[39m train_cv_parallel(X, y, mse, cv, epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2200\u001b[39m, learning_rate \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0001\u001b[39m)\n",
      "Cell \u001b[0;32mIn[2], line 92\u001b[0m, in \u001b[0;36mtrain_cv_parallel\u001b[0;34m(X, y, criterion, cv, epochs, learning_rate)\u001b[0m\n\u001b[1;32m     88\u001b[0m     optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mSGD(model\u001b[38;5;241m.\u001b[39mparameters(), lr \u001b[38;5;241m=\u001b[39m learning_rate, weight_decay \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.01\u001b[39m)\n\u001b[1;32m     90\u001b[0m     train_args\u001b[38;5;241m.\u001b[39mappend([model, criterion, train_loader, test_loader, optimizer, epochs])\n\u001b[0;32m---> 92\u001b[0m results \u001b[38;5;241m=\u001b[39m pool\u001b[38;5;241m.\u001b[39mmap(wrapper, train_args)\n\u001b[1;32m     93\u001b[0m model_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[38;5;241m0\u001b[39m], results))\n\u001b[1;32m     94\u001b[0m model_sets \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[38;5;241m1\u001b[39m], results))\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/multiprocessing/pool.py:367\u001b[0m, in \u001b[0;36mPool.map\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmap\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, iterable, chunksize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    363\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    364\u001b[0m \u001b[38;5;124;03m    Apply `func` to each element in `iterable`, collecting the results\u001b[39;00m\n\u001b[1;32m    365\u001b[0m \u001b[38;5;124;03m    in a list that is returned.\u001b[39;00m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[0;32m--> 367\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_map_async(func, iterable, mapstar, chunksize)\u001b[38;5;241m.\u001b[39mget()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/multiprocessing/pool.py:768\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    767\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 768\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[1;32m    769\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mready():\n\u001b[1;32m    770\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/multiprocessing/pool.py:765\u001b[0m, in \u001b[0;36mApplyResult.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    764\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwait\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 765\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event\u001b[38;5;241m.\u001b[39mwait(timeout)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/threading.py:622\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    620\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[1;32m    621\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 622\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cond\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[1;32m    623\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m         waiter\u001b[38;5;241m.\u001b[39macquire()\n\u001b[1;32m    321\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_results, model_sets = train_cv_parallel(X, y, mse, cv, epochs = 2200, learning_rate = 0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "faba0c38-1505-4a99-9670-7f1b0b51c918",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation average loss: 0.3216733979433775\n"
     ]
    }
   ],
   "source": [
    "cv_loss = sum(list(map(lambda x: x['validation_loss'][-1], model_results)))/len(model_results)\n",
    "print(f'Cross Validation average loss: {cv_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "05f7bc0d-9cce-4ce4-8692-42f386d4100d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "# predict on test data\n",
    "X_new = test_data.drop(columns = [\"SEQN\"]).values\n",
    "\n",
    "# scaler = StandardScaler()\n",
    "# scaler.fit(X_new)\n",
    "# X_new = scaler.transform(X_new)\n",
    "\n",
    "X_train = torch.tensor(X_new, dtype=torch.float32)\n",
    "\n",
    "predict = []\n",
    "\n",
    "for i in range(len(model_sets)):\n",
    "    predict.append(model_sets[i](X_train).view(1,-1))\n",
    "    \n",
    "predict = reduce(lambda a,b: torch.cat((a,b),axis=0), predict)\n",
    "\n",
    "predict_avg = torch.mean(predict, 0)\n",
    "\n",
    "\n",
    "submission = pd.DataFrame({'SEQN':test_data.SEQN,\n",
    "                           'y':predict_avg.view(-1).detach().numpy()})\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b66ad042-c7fe-4d7e-8ecf-22b93169d986",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5475],\n",
       "        [0.5425],\n",
       "        [0.5433],\n",
       "        ...,\n",
       "        [0.5455],\n",
       "        [0.5456],\n",
       "        [0.5486]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_sets[4](X_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
