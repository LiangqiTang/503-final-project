{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "0c50ec24",
      "metadata": {
        "id": "0c50ec24"
      },
      "source": [
        "# Lab 6: XGBoost and LightGBM"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this lab, we will go over two ways of utilizing gradient boosting in practice, namely XGBoost ([docs](https://xgboost.readthedocs.io/en/stable/index.html), [license](https://github.com/dmlc/xgboost/blob/master/LICENSE)) and LightGBM ([docs](https://lightgbm.readthedocs.io/en/stable/), [license](https://github.com/microsoft/LightGBM/blob/master/LICENSE)). Before going over the following code, we will discuss some basic theory on XGBoost and LightGBM (which you can find on the docs above). Then, we will return to this notebook in which we follow some of the relevant tutorials from their documentations."
      ],
      "metadata": {
        "id": "qWITOFpWZPGg"
      },
      "id": "qWITOFpWZPGg"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XGBoost"
      ],
      "metadata": {
        "id": "wephmtMVF3hA"
      },
      "id": "wephmtMVF3hA"
    },
    {
      "cell_type": "markdown",
      "source": [
        "We follow \"quick start tutorial\" for XGBoost ([link](https://xgboost.readthedocs.io/en/stable/get_started.html)), for which it may be good to check out this [article](https://xgboost.readthedocs.io/en/stable/python/sklearn_estimator.html) on \"Using the Scikit-Learn Estimator Interface\". Also, check out [XGBClassifier docs](https://xgboost.readthedocs.io/en/stable/python/python_api.html#xgboost.XGBClassifier)."
      ],
      "metadata": {
        "id": "eW_DoXgeumsR"
      },
      "id": "eW_DoXgeumsR"
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "V7zo7BRXEsCW"
      },
      "id": "V7zo7BRXEsCW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# read data\n",
        "data = load_iris()\n",
        "X_train, X_test, y_train, y_test = train_test_split(data['data'], data['target'], test_size=.2)"
      ],
      "metadata": {
        "id": "RTpCwMz9H8j3"
      },
      "id": "RTpCwMz9H8j3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create model instance\n",
        "bst = XGBClassifier(n_estimators=2, max_depth=2, learning_rate=1, objective='binary:logistic')"
      ],
      "metadata": {
        "id": "QAEfeG_lH_u5"
      },
      "id": "QAEfeG_lH_u5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fit model\n",
        "bst.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "2WTpLNnJIAj1"
      },
      "id": "2WTpLNnJIAj1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make predictions\n",
        "preds = bst.predict(X_test)\n",
        "preds"
      ],
      "metadata": {
        "id": "WaISG_qzIBbW"
      },
      "id": "WaISG_qzIBbW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LightGBM"
      ],
      "metadata": {
        "id": "qnzTXndeTRJ3"
      },
      "id": "qnzTXndeTRJ3"
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, we follow `sklearn_example.py` from LightGBM repository ([link](https://github.com/microsoft/LightGBM/blob/master/examples/python-guide/sklearn_example.py)). To do so, we need `regression.train` and `regression.test` files to be in the current directory. These files can be accessed [here](https://github.com/microsoft/LightGBM/tree/master/examples/regression)."
      ],
      "metadata": {
        "id": "gqzHCqtVjv1c"
      },
      "id": "gqzHCqtVjv1c"
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "import matplotlib.pyplot as plt\n",
        "import lightgbm as lgb"
      ],
      "metadata": {
        "id": "qnIl3WBmiqyL"
      },
      "id": "qnIl3WBmiqyL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load or create your dataset\n",
        "df_train = pd.read_csv(\"regression.train\", header=None, sep=\"\\t\")\n",
        "df_test = pd.read_csv(\"regression.test\", header=None, sep=\"\\t\")\n",
        "\n",
        "y_train = df_train[0]\n",
        "y_test = df_test[0]\n",
        "X_train = df_train.drop(0, axis=1)\n",
        "X_test = df_test.drop(0, axis=1)"
      ],
      "metadata": {
        "id": "dD104XqNkJVp"
      },
      "id": "dD104XqNkJVp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train\n",
        "gbm = lgb.LGBMRegressor(num_leaves=31, learning_rate=0.05, n_estimators=20)\n",
        "gbm.fit(X_train, y_train, eval_set=[(X_test, y_test)], eval_metric=\"l1\", callbacks=[lgb.early_stopping(5)])"
      ],
      "metadata": {
        "id": "af17Jj1ZkNWx"
      },
      "id": "af17Jj1ZkNWx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# predict\n",
        "y_pred = gbm.predict(X_test, num_iteration=gbm.best_iteration_)"
      ],
      "metadata": {
        "id": "xAD4YprIkO3F"
      },
      "id": "xAD4YprIkO3F",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate\n",
        "rmse_test = mean_squared_error(y_test, y_pred) ** 0.5\n",
        "print(f\"The RMSE of prediction is: {rmse_test}\")"
      ],
      "metadata": {
        "id": "-ye5dJvlkWq_"
      },
      "id": "-ye5dJvlkWq_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# feature importances\n",
        "print(f\"Feature importances: {list(gbm.feature_importances_)}\")"
      ],
      "metadata": {
        "id": "8wOE8TBlkXyA"
      },
      "id": "8wOE8TBlkXyA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# self-defined eval metric, which here is root mean squared logarithmic error (RMSLE)\n",
        "# f(y_true: array, y_pred: array) -> name: str, eval_result: float, is_higher_better: bool\n",
        "def rmsle(y_true, y_pred):\n",
        "    return \"RMSLE\", np.sqrt(np.mean(np.power(np.log1p(y_pred) - np.log1p(y_true), 2))), False"
      ],
      "metadata": {
        "id": "g7b15hhgkf8x"
      },
      "id": "g7b15hhgkf8x",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train with custom eval function\n",
        "gbm.fit(X_train, y_train, eval_set=[(X_test, y_test)], eval_metric=rmsle, callbacks=[lgb.early_stopping(5)])\n",
        "\n",
        "# predict\n",
        "y_pred = gbm.predict(X_test, num_iteration=gbm.best_iteration_)\n",
        "\n",
        "# evaluate\n",
        "rmsle_test = rmsle(y_test, y_pred)[1]\n",
        "print(f\"The RMSLE of prediction is: {rmsle_test}\")"
      ],
      "metadata": {
        "id": "9cVK0rmd2J9O"
      },
      "id": "9cVK0rmd2J9O",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# find optimal parameters using GridSearchCV\n",
        "\n",
        "estimator = lgb.LGBMRegressor(num_leaves=31)\n",
        "\n",
        "param_grid = {\"learning_rate\": [0.01, 0.1, 1], \"n_estimators\": [20, 40]}\n",
        "\n",
        "gbm = GridSearchCV(estimator, param_grid, cv=3)\n",
        "gbm.fit(X_train, y_train)\n",
        "\n",
        "print(f\"Best parameters found by grid search are: {gbm.best_params_}\")"
      ],
      "metadata": {
        "id": "Tx3gc7rJksqk"
      },
      "id": "Tx3gc7rJksqk",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we follow `plot_example.py` from the same repository ([link](https://github.com/microsoft/LightGBM/blob/master/examples/python-guide/plot_example.py)). You may wish to look at [Python Quick Start](https://lightgbm.readthedocs.io/en/latest/Python-Intro.html) from LightGBM docs."
      ],
      "metadata": {
        "id": "FGjiuj20mEEh"
      },
      "id": "FGjiuj20mEEh"
    },
    {
      "cell_type": "code",
      "source": [
        "# load or create your dataset\n",
        "df_train = pd.read_csv(\"regression.train\", header=None, sep=\"\\t\")\n",
        "df_test = pd.read_csv(\"regression.test\", header=None, sep=\"\\t\")\n",
        "\n",
        "y_train = df_train[0]\n",
        "y_test = df_test[0]\n",
        "X_train = df_train.drop(0, axis=1)\n",
        "X_test = df_test.drop(0, axis=1)"
      ],
      "metadata": {
        "id": "Zz5oNCwbmQWr"
      },
      "id": "Zz5oNCwbmQWr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create dataset for lightgbm\n",
        "lgb_train = lgb.Dataset(X_train, y_train)\n",
        "lgb_test = lgb.Dataset(X_test, y_test, reference=lgb_train)"
      ],
      "metadata": {
        "id": "BpnR5NgRmR-H"
      },
      "id": "BpnR5NgRmR-H",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# specify your configurations as a dict\n",
        "params = {\"num_leaves\": 5, \"metric\": (\"l1\", \"l2\"), \"verbose\": 0}\n",
        "\n",
        "evals_result = {}  # to record eval results for plotting"
      ],
      "metadata": {
        "id": "_r0RfxFBmTGm"
      },
      "id": "_r0RfxFBmTGm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train\n",
        "gbm = lgb.train(\n",
        "    params,\n",
        "    lgb_train,\n",
        "    num_boost_round=100,\n",
        "    valid_sets=[lgb_train, lgb_test],\n",
        "    feature_name=[f\"f{i + 1}\" for i in range(X_train.shape[-1])],\n",
        "    categorical_feature=[21],\n",
        "    callbacks=[lgb.log_evaluation(10), lgb.record_evaluation(evals_result)],\n",
        ")"
      ],
      "metadata": {
        "id": "hlOfNFoQmWxw"
      },
      "id": "hlOfNFoQmWxw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_pred = gbm.predict(X_test)"
      ],
      "metadata": {
        "id": "60jas6x66iSt"
      },
      "id": "60jas6x66iSt",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot metrics recorded during training\n",
        "ax = lgb.plot_metric(evals_result, metric=\"l1\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "LJcCwnMGmYVa"
      },
      "id": "LJcCwnMGmYVa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot feature importances\n",
        "ax = lgb.plot_importance(gbm, max_num_features=10)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "LYBchjTbmjbZ"
      },
      "id": "LYBchjTbmjbZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot split value histogram\n",
        "ax = lgb.plot_split_value_histogram(gbm, feature=\"f26\", bins=\"auto\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "aivlyo_mmkSR"
      },
      "id": "aivlyo_mmkSR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting 54th tree, use categorical feature to split\n",
        "ax = lgb.plot_tree(gbm, tree_index=53, figsize=(15, 15), show_info=[\"split_gain\"])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Q4Jll-lemky6"
      },
      "id": "Q4Jll-lemky6",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "jupytext": {
      "cell_metadata_filter": "-all",
      "formats": "Rmd,ipynb",
      "main_language": "python"
    },
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}